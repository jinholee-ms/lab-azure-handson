{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca399873",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "본 `ipynb` 은 `Python=3.12` 에서 작성하였습니다. Package dependency 를 해결하기 위해 아래 cell 을 실행해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe7d7e",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8445dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U dotenv openai azure-ai-projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496ba36",
   "metadata": {},
   "source": [
    "## Load environment variables from a .env file\n",
    "secret 노출을 피하고 notebook 들간의 일관된 환경변수를 설정하기 위해 `dotenv` 을 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14085ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6acc8",
   "metadata": {},
   "source": [
    "# Optimization\n",
    "OpenAI 는 다양한 gpt-5 매개변수를 제공한다. 이를 통해 성능과 비용을 선택적으로 개선해 나갈 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00416a13",
   "metadata": {},
   "source": [
    "## Verbosity\n",
    "'재잘거림' 의 정도를 결정한다. 가끔씩 gpt 가 너무 친철하다고 생각할 때 이용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "verbosity = {}\n",
    "response = {}\n",
    "for v in [\"low\", \"medium\", \"high\"]: # medium 이 default\n",
    "    response[v] = client.responses.create(\n",
    "        model=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "        input=\"내가 오늘 화성에 한 번 가보고 싶은데, 어떻게 갈 수 있을까 ?\",\n",
    "        text={\"verbosity\": v},\n",
    "    )\n",
    "    verbosity[v] = [response[v].usage.output_tokens]\n",
    "\n",
    "# pandas 로 결과 출력\n",
    "pd.DataFrame(verbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aee009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주의해야 할 점이, max_output_tokens 이 실제 생성되는 tokens 수보다 작으면 output_text 가 리턴되지 않는다.\n",
    "# 차라리, streaming 으로 받아서 처리하는게 좋다.\n",
    "response = client.responses.create(\n",
    "    model=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "    input=\"내가 오늘 화성에 한 번 가보고 싶은데, 어떻게 갈 수 있을까 ?\",\n",
    "    max_output_tokens=1000,\n",
    ")\n",
    "\n",
    "print(\"====== 출력 ======\")\n",
    "for item in response.output:\n",
    "    if item.type == \"message\":\n",
    "        for content in item.content:\n",
    "            print(content.text)\n",
    "print(\"====== 사용량 ======\")\n",
    "print(response.usage.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2939af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b219f160",
   "metadata": {},
   "source": [
    "## Context-Free Grammar (CFG)\n",
    "출력되는 output 을 regex 와 같은 도구를 통해 문법을 지키도록 할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "    input=\"generate_name 을 호출해서 새로 태어나는 아이의 이름을 지어줘.\",\n",
    "    tools=[\n",
    "        {\n",
    "            \"type\": \"custom\",\n",
    "            \"name\": \"generate_name\",\n",
    "            \"description\": \"이름을 지어주는 도구입니다.\",\n",
    "            \"format\": {\n",
    "                \"type\": \"grammar\",\n",
    "                \"syntax\": \"regex\",\n",
    "                \"definition\": \"^이[가-힣]{1,2}$\",\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"====== 출력 ======\")\n",
    "for item in response.output:\n",
    "    if item.type == \"custom_tool_call\":\n",
    "        print(item.input)\n",
    "print(\"====== 사용량 ======\")\n",
    "print(response.usage.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c38c52",
   "metadata": {},
   "source": [
    "## Minimal Reasoning\n",
    "추론의 정도를 조절한다. RAG 의 정보가 많지 않거나 task 가 깊은 추론을 요구하지 않는다면, 조절해볼만도 하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8680b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.responses.create(\n",
    "    model=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "    input=\"물에 어떤 불순물이 들어갔는데, 100도가 되도 물이 끓지 않아. 어떤 불순물이 들어간 걸까 ?\",\n",
    "    reasoning={\"effort\": \"minimal\"},    # \"minimal\", \"high\"\n",
    ")\n",
    "\n",
    "print(\"====== 출력 ======\")\n",
    "for item in response.output:\n",
    "    if item.type == \"message\":\n",
    "        for content in item.content:\n",
    "            print(content.text)\n",
    "print(\"====== 사용량 ======\")\n",
    "print(response.usage.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84d3c2",
   "metadata": {},
   "source": [
    "# Parallel tool calling\n",
    "Tool calling 할때 병렬처리 지원한다. Client-side 에서 async / multi-threads 기반으로 운용한다면 보다 빠른 처리가 가능하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b06dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_age\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_age\",\n",
    "            \"description\": \"인물의 나이를 알려주는 함수입니다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": { \"type\": \"string\" }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_height\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_height\",\n",
    "            \"description\": \"인물의 키를 알려주는 함수입니다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": { \"type\": \"string\" }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"name\": \"get_weight\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_weight\",\n",
    "            \"description\": \"인물의 체중을 알려주는 함수입니다.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"name\": { \"type\": \"string\" }\n",
    "                },\n",
    "                \"required\": [\"name\"]\n",
    "            },\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"이진호의 나이과 키와 체중을 알려줘.\",\n",
    "    tools=tools,\n",
    "    parallel_tool_calls=True,  # 병렬로 도구를 호출합니다.\n",
    ")\n",
    "print(\"====== 출력 (gpt-5 병렬 on)======\")\n",
    "print(response.model_dump_json(indent=2, exclude_none=True))\n",
    "response = client.responses.create(\n",
    "    model=\"gpt-5\",\n",
    "    input=\"이진호의 나이과 키와 체중을 알려줘.\",\n",
    "    tools=tools,\n",
    "    parallel_tool_calls=False,  # 병렬로 도구를 호출합니다.\n",
    ")\n",
    "print(\"====== 출력 (gpt-5 병렬 off)======\")\n",
    "print(response.model_dump_json(indent=2, exclude_none=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-lab-azure-handson-ai-foundry-001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
