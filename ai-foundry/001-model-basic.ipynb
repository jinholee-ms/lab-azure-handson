{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca399873",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "본 `ipynb` 은 `Python=3.12` 에서 작성하였습니다. Package dependency 를 해결하기 위해 아래 cell 을 실행해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fe7d7e",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8445dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U dotenv openai azure-ai-projects azure-monitor-opentelemetry opentelemetry-instrumentation-openai-v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e496ba36",
   "metadata": {},
   "source": [
    "## Load environment variables from a .env file\n",
    "secret 노출을 피하고 notebook 들간의 일관된 환경변수를 설정하기 위해 `dotenv` 을 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14085ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_AI_FOUNDRY_PROJECT_ENDPOINT = os.getenv(\"AZURE_AI_FOUNDRY_PROJECT_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85fb32e",
   "metadata": {},
   "source": [
    "# Connect azure monitor of AI Foundry project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a8028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input/output message content를 캡처하기 위해 환경변수를 설정합니다.\n",
    "import os\n",
    "\n",
    "os.environ[\"OTEL_INSTRUMENTATION_GENAI_CAPTURE_MESSAGE_CONTENT\"] = \"true\"\n",
    "os.environ[\"AZURE_TRACING_GEN_AI_CONTENT_RECORDING_ENABLED\"] = \"true\"\n",
    "\n",
    "# from azure.ai.projects import AIProjectClient\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry.instrumentation.openai_v2 import OpenAIInstrumentor\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.identity import AzureCliCredential\n",
    "\n",
    "# OpenAI API 호출을 자동으로 계측하기 위해 OpenAIInstrumentor를 사용합니다.\n",
    "OpenAIInstrumentor().instrument()\n",
    "\n",
    "# AIProjectClient를 사용하여 Azure AI Foundry 프로젝트에 연결합니다.\n",
    "# API Key를 TokenCredential로 변환합니다.\n",
    "project_client = AIProjectClient(\n",
    "    credential=AzureCliCredential(),\n",
    "    endpoint=AZURE_AI_FOUNDRY_PROJECT_ENDPOINT,\n",
    ")\n",
    "# Azure Monitor를 구성합니다.\n",
    "configure_azure_monitor(connection_string=project_client.telemetry.get_application_insights_connection_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca6acc8",
   "metadata": {},
   "source": [
    "# OpenAI Generative APIs\n",
    "OpenAI 는 Frontier LLM 모델을 서비스한다. Azure 는 OpenAI 의 동일한 모델들과 APIs 를 서비스하고 있으며, Python 에서는 `openai` package 를 통해서 Azure OpenAI (AOAI) 의 client 를 생성할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024c1cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    api_version=AZURE_OPENAI_API_VERSION,\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00416a13",
   "metadata": {},
   "source": [
    "## Simply Q&A Behavior\n",
    "가장 초기에 나온 chat completions API 를 통해 question 에 대한 answer 를 synthesis 해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ffd2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [required] 꼭 gpt-4.1 모델이 Azure OpenAI 에서 배포되어 있어야 한다.\n",
    "r = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"GPT 를 쓸때 비용을 절감할 수 있는 방법은 어떤게 있을까 ?\"}],\n",
    ")\n",
    "\n",
    "print(\"=== Response Message ===\")\n",
    "print(r.choices[0].message.content)\n",
    "print(\"\\n=== Response Usage ===\")\n",
    "print(r.usage.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2081f20",
   "metadata": {},
   "source": [
    "## Advanced Q&A using Assistants API\n",
    "Assistants API 는 Conversational API 이다. 단순 answer 를 생성해내는 것을 넘어 사용자와 모델의 대화를 제어할 수 있다. 여전히 beta 이고 벌써 deprecated 된단다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6812c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assistants API 를 통해 Q&A 를 수행합니다.\n",
    "assistant = client.beta.assistants.create(model=\"gpt-4.1\")\n",
    "\n",
    "thread = client.beta.threads.create()\n",
    "client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"GPT 를 쓸때 비용을 절감할 수 있는 방법은 어떤게 있을까 ?\",\n",
    ")\n",
    "\n",
    "run = client.beta.threads.runs.create(thread_id=thread.id, assistant_id=assistant.id)\n",
    "\n",
    "# 폴링 (간단 예시)\n",
    "while True:\n",
    "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
    "    if run.status == \"completed\":\n",
    "        break\n",
    "\n",
    "messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
    "print(\"=== Response Message ===\")\n",
    "print(messages.data[0].content[0].text.value)\n",
    "print(\"\\n=== Run Usage ===\")\n",
    "print(run.usage.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3b6abb",
   "metadata": {},
   "source": [
    "## Other approach Q&A using Responses API\n",
    "가장 최신에 공개된 응답형 API 이다. 각 dialog 마다 `response id` 가 주어지고 이를 통해 conversation history 를 제어할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43934a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Responses API 를 통해 Q&A 를 수행합니다.\n",
    "r = client.responses.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    input=[{\"role\": \"user\", \"content\": \"GPT 를 쓸때 비용을 절감할 수 있는 방법은 어떤게 있을까 ?\"}],\n",
    "    previous_response_id=None,\n",
    ")\n",
    "\n",
    "print(\"=== Response Message ===\")\n",
    "print(r.output_text)\n",
    "print(\"\\n=== Response Usage ===\")\n",
    "print(r.usage.model_dump_json(indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-lab-azure-handson-ai-foundry-001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
