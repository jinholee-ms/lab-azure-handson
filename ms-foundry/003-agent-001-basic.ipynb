{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5871f48b",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "본 `ipynb` 은 `Python=3.12` 에서 작성하였습니다. Package dependency 를 해결하기 위해 아래 cell 을 실행해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab36d7",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U agent-framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72ff9b",
   "metadata": {},
   "source": [
    "## Load environment variables from a .env file\n",
    "secret 노출을 피하고 notebook 들간의 일관된 환경변수를 설정하기 위해 `dotenv` 을 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "AZURE_MS_FOUNDRY_PROJECT_ENDPOINT = os.getenv(\"AZURE_MS_FOUNDRY_PROJECT_ENDPOINT\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015437c",
   "metadata": {},
   "source": [
    "# Microsoft Agent Framework\n",
    "다른 agent framework 과 비슷한 기능을 제공한다. gpt 모델의 client 를 만들고 agent 를 생성해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee48a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent_framework.azure import AzureAIClient\n",
    "from azure.identity.aio import DefaultAzureCredential\n",
    "\n",
    "agent = AzureAIClient(\n",
    "    project_endpoint=AZURE_MS_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    credential=DefaultAzureCredential(),\n",
    "    model_deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    ").as_agent(name=\"buddy-agent\", instructions=\"너는 내 친구야.\")\n",
    "\n",
    "result = await agent.run(\"안녕 내 이름은 이진호야. 너는 누구니 ?\")\n",
    "print(result.text)\n",
    "print(\"--------------------------------\")\n",
    "result = await agent.run(\"내 이름은 뭐지 ?\")\n",
    "print(result.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991f40a3",
   "metadata": {},
   "source": [
    "대화 이력을 기억하기 위해선 thread 를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fb8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = agent.get_new_thread()\n",
    "\n",
    "result = await agent.run(\"안녕 내 이름은 이진호야. 너는 누구니 ?\", thread=t1)\n",
    "print(result.text)\n",
    "print(\"--------------------------------\")\n",
    "result = await agent.run(\"내 이름은 뭐지 ?\", thread=t1)\n",
    "print(result.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109b2bbe",
   "metadata": {},
   "source": [
    "Function calling 도 지원한다. Agent 이기 때문에 tool_calling 에 대한 message 도 알아서 처리해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1448c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from pydantic import Field\n",
    "from agent_framework import tool\n",
    "\n",
    "@tool(name=\"weather_tool\", description=\"Retrieves weather information for any location\")\n",
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C.\"\n",
    "\n",
    "agent = AzureAIClient(\n",
    "    project_endpoint=AZURE_MS_FOUNDRY_PROJECT_ENDPOINT,\n",
    "    credential=DefaultAzureCredential(),\n",
    "    model_deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    ").as_agent(\n",
    "    name=\"weather-agent\", instructions=\"너는 날씨 정보를 제공하는 도우미야.\", tools=get_weather,\n",
    ")\n",
    "\n",
    "result = await agent.run(\"서울의 날씨는 어때 ?\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "387d3044",
   "metadata": {},
   "source": [
    "## Human-in-the-Loop\n",
    "위 basic 한 내용은 그닥 어렵지 않다. 다소 advanced 한 기능을 한 번 넣어보면, HITL 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cee973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from agent_framework import ChatAgent, ChatMessage, Role, tool\n",
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "\n",
    "@tool\n",
    "def get_weather(location: Annotated[str, \"The city and state, e.g. San Francisco, CA\"]) -> str:\n",
    "    \"\"\"Get the current weather for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C.\"\n",
    "\n",
    "@tool(approval_mode=\"always_require\")\n",
    "def get_weather_detail(location: Annotated[str, \"The city and state, e.g. San Francisco, CA\"]) -> str:\n",
    "    \"\"\"Get detailed weather information for a given location.\"\"\"\n",
    "    return f\"The weather in {location} is cloudy with a high of 15°C, humidity 88%.\"\n",
    "\n",
    "\n",
    "agent = ChatAgent(\n",
    "    chat_client=AzureOpenAIResponsesClient(\n",
    "        endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        api_key=AZURE_OPENAI_API_KEY,\n",
    "        api_version=AZURE_OPENAI_API_VERSION,\n",
    "        deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "    ),\n",
    "    name=\"WeatherAgent\",\n",
    "    instructions=\"You are a helpful weather assistant.\",\n",
    "    tools=[get_weather, get_weather_detail],\n",
    ")\n",
    "\n",
    "thread = agent.get_new_thread()\n",
    "result = await agent.run(\"뉴욕의 상세한 날씨는 어때?\", thread=thread)\n",
    "if result.user_input_requests:\n",
    "    for user_input_needed in result.user_input_requests:\n",
    "        print(f\"Function: {user_input_needed.function_call.name}\")\n",
    "        print(f\"Arguments: {user_input_needed.function_call.arguments}\")\n",
    "        approval = input(f\"Do you approve the function call? (y/n)\")\n",
    "        approval = True if approval == \"y\" else False\n",
    "        approval_message = ChatMessage(\n",
    "            role=Role.USER, \n",
    "            contents=[user_input_needed.to_function_approval_response(approval)]\n",
    "        )\n",
    "\n",
    "        final_result = await agent.run(approval_message, thread=thread)\n",
    "        print(final_result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e2ad9c",
   "metadata": {},
   "source": [
    "## Agent Observability\n",
    "Microsoft Foundry 의 기능을 이용하면 remote 에서 동작하고 있는 agent 의 visibility 를 로깅할 수 있다. 아래를 살펴보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefc25e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import os\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework import ChatAgent\n",
    "from agent_framework import tool\n",
    "from agent_framework.observability import create_resource, enable_instrumentation, get_tracer\n",
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.ai.projects.aio import AIProjectClient\n",
    "from azure.identity.aio import AzureCliCredential\n",
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "from opentelemetry.trace import SpanKind\n",
    "from opentelemetry.trace.span import format_trace_id\n",
    "from pydantic import Field\n",
    "\n",
    "@tool(approval_mode=\"never_require\")\n",
    "async def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    await asyncio.sleep(randint(0, 10) / 10.0)  # Simulate a network call\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}°C.\"\n",
    "\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=AZURE_MS_FOUNDRY_PROJECT_ENDPOINT, credential=DefaultAzureCredential(),\n",
    ")\n",
    "\n",
    "# Microsoft Foundry 에서 제공하는 Application Insights 를 사용하기 위해 필요한 설정\n",
    "conn_string = await project_client.telemetry.get_application_insights_connection_string()\n",
    "# Application Insights 를 사용하기 위해 필요한 설정\n",
    "configure_azure_monitor(\n",
    "    connection_string=conn_string,\n",
    "    enable_live_metrics=True,\n",
    "    resource=create_resource(),\n",
    "    enable_performance_counters=False,\n",
    ")\n",
    "# 민감한 데이터 수집 설정 (프로덕션 환경에서는 비활성화 필요)\n",
    "enable_instrumentation(enable_sensitive_data=True)\n",
    "\n",
    "with get_tracer().start_as_current_span(\"Weather Agent Chat\", kind=SpanKind.CLIENT) as current_span:\n",
    "    print(f\"Trace ID: {format_trace_id(current_span.get_span_context().trace_id)}\")\n",
    "    agent = ChatAgent(\n",
    "        chat_client=AzureOpenAIResponsesClient(\n",
    "            endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "            api_version=AZURE_OPENAI_API_VERSION,\n",
    "            deployment_name=AZURE_OPENAI_CHAT_DEPLOYMENT,\n",
    "        ),\n",
    "        tools=get_weather,\n",
    "        name=\"WeatherAgent\",\n",
    "        instructions=\"You are a weather assistant.\",\n",
    "        id=\"weather-agent\",\n",
    "    )\n",
    "\n",
    "    thread = agent.get_new_thread()\n",
    "    for question in [\"삿포로 날씨는 어때 ?\", \"상하이 날씨와 비교해서 어디가 더 좋아?\", \"왜 하늘이 파래?\"]:\n",
    "        print(f\"\\nUser: {question}\")\n",
    "        print(f\"{agent.name}: \", end=\"\")\n",
    "        async for update in agent.run_stream(\n",
    "            question,\n",
    "            thread=thread,\n",
    "        ):\n",
    "            if update.text:\n",
    "                print(update.text, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-lab-azure-handson-ms-foundry-001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
