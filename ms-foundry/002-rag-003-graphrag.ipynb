{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5871f48b",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "본 `ipynb` 은 `Python=3.12` 에서 작성하였습니다. Package dependency 를 해결하기 위해 아래 cell 을 실행해주세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ab36d7",
   "metadata": {},
   "source": [
    "## Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a0950cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U graphrag azure-ai-documentintelligence langchain langchain-community langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b72ff9b",
   "metadata": {},
   "source": [
    "## Load environment variables from a .env file\n",
    "secret 노출을 피하고 notebook 들간의 일관된 환경변수를 설정하기 위해 `dotenv` 을 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d468ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT\")\n",
    "AZURE_OPENAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_AI_SEARCH_ENDPOINT = os.getenv(\"AZURE_AI_SEARCH_ENDPOINT\")\n",
    "AZURE_AI_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_AI_SEARCH_ADMIN_KEY\")\n",
    "AZURE_DOCUMENTINTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENTINTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENTINTELLIGENCE_API_KEY = os.getenv(\"AZURE_DOCUMENTINTELLIGENCE_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822388c",
   "metadata": {},
   "source": [
    "# Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f709f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.doc_intelligence import AzureAIDocumentIntelligenceLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "loader = AzureAIDocumentIntelligenceLoader(\n",
    "    api_endpoint=AZURE_DOCUMENTINTELLIGENCE_ENDPOINT,\n",
    "    api_key=AZURE_DOCUMENTINTELLIGENCE_API_KEY,\n",
    "    file_path=\"./resources/대한민국 헌법.pdf\",\n",
    "    api_model=\"prebuilt-read\",\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "chunks = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32da022",
   "metadata": {},
   "source": [
    "# Knowledge Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c733dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 아래 명령은 터미널에서 실행하세요.\n",
    "# %run graphrag --init --root_dir ./graphrag\n",
    "# %run cp settings.yaml ./graphrag/settings.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e7753c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "Path(\"graphrag/input\").mkdir(parents=True, exist_ok=True)\n",
    "with open(\"graphrag/input/chunks.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for chunk in chunks:\n",
    "        f.write(chunk.page_content + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a061c617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import graphrag.api as api\n",
    "from graphrag.config.load_config import load_config\n",
    "from graphrag.index.typing.pipeline_run_result import PipelineRunResult\n",
    "\n",
    "root_dir = Path(\"./graphrag\")\n",
    "\n",
    "# 1) settings.yaml + .env 로부터 GraphRAG 설정 로드\n",
    "config = load_config(root_dir)\n",
    "\n",
    "# 2) 인덱싱 파이프라인 실행\n",
    "index_result: list[PipelineRunResult] = await api.build_index(config=config)\n",
    "\n",
    "# 3) 워크플로우별 성공/실패 출력\n",
    "for workflow_result in index_result:\n",
    "    status = \"success\" if not workflow_result.errors else f\"error\\n{workflow_result.errors}\"\n",
    "    print(f\"Workflow: {workflow_result.workflow}\\tStatus: {status}\")\n",
    "\n",
    "# 4) 인덱싱 결과인 parquet 파일 로드 (q&a에서 사용)\n",
    "entities = pd.read_parquet(root_dir / \"output\" / \"entities.parquet\")\n",
    "communities = pd.read_parquet(root_dir / \"output\" / \"communities.parquet\")\n",
    "community_reports = pd.read_parquet(root_dir / \"output\" / \"community_reports.parquet\")\n",
    "\n",
    "print(\"entities.head():\")\n",
    "print(entities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50394dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import graphrag.api as api\n",
    "from graphrag.config.load_config import load_config\n",
    "\n",
    "PROJECT_DIR = Path(\"./graphrag\")\n",
    "config = load_config(PROJECT_DIR)\n",
    "\n",
    "# 인덱싱 후 생성된 parquet 로드\n",
    "entities = pd.read_parquet(PROJECT_DIR / \"output\" / \"entities.parquet\")\n",
    "communities = pd.read_parquet(PROJECT_DIR / \"output\" / \"communities.parquet\")\n",
    "community_reports = pd.read_parquet(PROJECT_DIR / \"output\" / \"community_reports.parquet\")\n",
    "\n",
    "question = \"대통령은 누구이고, 어떤 책임과 의무를 가져 ?\"\n",
    "\n",
    "# ---- Global Search ----\n",
    "response, context = await api.global_search(\n",
    "    config=config,\n",
    "    entities=entities,\n",
    "    communities=communities,\n",
    "    community_reports=community_reports,\n",
    "    community_level=2,                # 커뮤니티 계층 (보통 1~3)\n",
    "    dynamic_community_selection=False, # true 로 하면 질문에 맞게 커뮤니티 자동 선택\n",
    "    response_type=\"Multiple Paragraphs\",\n",
    "    query=question,\n",
    ")\n",
    "print(\"=== Answer ===\")\n",
    "print(response)\n",
    "print(\"\\n=== Context (debug) ===\")\n",
    "print(context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485ae0d9",
   "metadata": {},
   "source": [
    "# Knowledge Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e510ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# metadata 에 있는 값들을 document 에 들어가기에 중복되는 key 들을 제거한다.\n",
    "for d in chunks:\n",
    "    d.metadata.pop(\"content\", None)          # 충돌 키 제거\n",
    "    d.metadata.pop(\"content_vector\", None)   # (안전)\n",
    "    d.metadata.pop(\"id\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e655c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "\n",
    "index_name = \"constitution\"\n",
    "\n",
    "emb = AzureOpenAIEmbeddings(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT,\n",
    "    openai_api_version=AZURE_OPENAI_API_VERSION,\n",
    ")\n",
    "\n",
    "# 여기선 index name 이 없을 때 schema 를 추론하여 자동 생성해준다.\n",
    "vs = AzureSearch(\n",
    "    azure_search_endpoint=AZURE_AI_SEARCH_ENDPOINT,\n",
    "    azure_search_key=AZURE_AI_SEARCH_ADMIN_KEY,\n",
    "    index_name=index_name,\n",
    "    embedding_function=emb.embed_query,\n",
    ")\n",
    "vs.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84baa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a similarity search\n",
    "docs = vs.similarity_search(\n",
    "    query=question,\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "for idx, doc in enumerate(docs):\n",
    "    print(f\"\\n=== Document {idx + 1} ===\")\n",
    "    print(doc.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-lab-azure-handson-ms-foundry-001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
