{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip -q install -U dotenv azure-ai-ml azure-identity azureml-mlflow mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables from a .env file\n",
    "secret 노출을 피하고 notebook 들간의 일관된 환경변수를 설정하기 위해 `dotenv` 을 이용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "AZURE_AML_SUBSCRIPTION_ID = os.getenv(\"AZURE_AML_SUBSCRIPTION_ID\")\n",
    "AZURE_AML_RESOURCE_GROUP = os.getenv(\"AZURE_AML_RESOURCE_GROUP\")\n",
    "AZURE_AML_WORKSPACE = os.getenv(\"AZURE_AML_WORKSPACE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Azure Machine Learning cilent\n",
    "Azure Machine Learning 의 Client 객체인 `MLClient` 을 생성한다. 본 예제는 Azure CLI 로그인 Credential 을 사용하고 있다. 터미널에서 `az login` 을 정상적으로 완료하여야 한다. `az` 명령어가 설치되어 있지 않다면 [Azure CLI 설치하는 방법](https://learn.microsoft.com/ko-kr/cli/azure/install-azure-cli?view=azure-cli-latest) 을 참고한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.ml import MLClient\n",
    "\n",
    "ml_client = MLClient(\n",
    "    DefaultAzureCredential(),\n",
    "    AZURE_AML_SUBSCRIPTION_ID,\n",
    "    AZURE_AML_RESOURCE_GROUP,\n",
    "    AZURE_AML_WORKSPACE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Azure Machine Learning cilent\n",
    "Azure Machine Learning 의 Client 객체인 `MLClient` 을 생성한다. 본 예제는 Azure CLI 로그인 Credential 을 사용하고 있다. 터미널에서 `az login` 을 정상적으로 완료하여야 한다. `az` 명령어가 설치되어 있지 않다면 [Azure CLI 설치하는 방법](https://learn.microsoft.com/ko-kr/cli/azure/install-azure-cli?view=azure-cli-latest) 을 참고한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "workspace_ml_client = MLClient(\n",
    "    DefaultAzureCredential(), AZURE_AML_SUBSCRIPTION_ID, AZURE_AML_RESOURCE_GROUP, AZURE_AML_WORKSPACE\n",
    ")\n",
    "registry_ml_client = MLClient(\n",
    "    DefaultAzureCredential(), AZURE_AML_SUBSCRIPTION_ID, AZURE_AML_RESOURCE_GROUP, registry_name=\"azureml\",\n",
    ")\n",
    "\n",
    "experiment_name = \"funtuning-mmdetection-yolof-coco\"\n",
    "timestamp = str(int(time.time()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Fine Tuning\n",
    "AML model registry 에 등록되어 있는 모델을 사용하여 fine tuning 을 해본다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create compute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import AmlCompute\n",
    "from azure.core.exceptions import ResourceNotFoundError\n",
    "\n",
    "cpu_cluster_name = \"cpu-cluster-001\"\n",
    "try:\n",
    "    _ = workspace_ml_client.compute.get(cpu_cluster_name)\n",
    "    print(f\"Found existing compute target ({cpu_cluster_name}).\")\n",
    "except ResourceNotFoundError:\n",
    "    print(f\"Creating a new compute target ({cpu_cluster_name})...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=cpu_cluster_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_D12_v2\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "    )\n",
    "    workspace_ml_client.begin_create_or_update(compute_config).result()\n",
    "    \n",
    "gpu_cluster_name = \"gpu-cluster-001\"\n",
    "try:\n",
    "    _ = workspace_ml_client.compute.get(gpu_cluster_name)\n",
    "    print(f\"Found existing compute target ({gpu_cluster_name}).\")\n",
    "except ResourceNotFoundError:\n",
    "    print(f\"Creating a new compute target ({gpu_cluster_name})...\")\n",
    "    compute_config = AmlCompute(\n",
    "        name=gpu_cluster_name,\n",
    "        type=\"amlcompute\",\n",
    "        size=\"Standard_NC6s_v3\",\n",
    "        idle_time_before_scale_down=120,\n",
    "        min_instances=0,\n",
    "        max_instances=4,\n",
    "        tier=\"LowPriority\",\n",
    "    )\n",
    "    workspace_ml_client.begin_create_or_update(compute_config).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus_per_node = 0\n",
    "gpu_count_found = False\n",
    "for compute_sku in workspace_ml_client.compute.list_sizes():\n",
    "    if compute_sku.name.lower() == \"Standard_NC96ads_A100_v4\".lower():\n",
    "        gpus_per_node = compute_sku.gpus\n",
    "        gpu_count_found = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mmdetection_model_name = \"yolof_r50_c5_8x8_1x_coco\"\n",
    "aml_registry_model_name = \"mmd-3x-yolof_r50_c5_8x8_1x_coco\"\n",
    "foundation_model = max(registry_ml_client.models.list(name=aml_registry_model_name), key=lambda x: int(x.version))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "dataset_parent_dir = \"./resources/training-mmd-object-detection\"\n",
    "dataset_dir = f\"{dataset_parent_dir}/data/odFridgeObjects\"\n",
    "sample_image = os.path.join(dataset_dir, \"images\", \"31.jpg\")\n",
    "Image(filename=sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Data\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "my_data = Data(\n",
    "    path=dataset_dir,\n",
    "    type=AssetTypes.URI_FOLDER,\n",
    "    description=\"Fridge-items images Object detection\",\n",
    "    name=\"fridge-items-images-object-detection\",\n",
    ")\n",
    "\n",
    "uri_folder_data_asset = workspace_ml_client.data.create_or_update(my_data)\n",
    "\n",
    "print(uri_folder_data_asset)\n",
    "print(\"\")\n",
    "print(\"Path to folder in Blob Storage:\")\n",
    "print(uri_folder_data_asset.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert annotation file to JSONL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "\n",
    "# We will copy each JSONL file within its related MLTable folder\n",
    "training_mltable_path = os.path.join(dataset_parent_dir, \"data/training-mltable-folder\")\n",
    "validation_mltable_path = os.path.join(dataset_parent_dir, \"data/validation-mltable-folder\")\n",
    "\n",
    "# Create the folders if they don't exist\n",
    "os.makedirs(training_mltable_path, exist_ok=True)\n",
    "os.makedirs(validation_mltable_path, exist_ok=True)\n",
    "\n",
    "train_validation_ratio = 5\n",
    "\n",
    "# Path to the training and validation files\n",
    "train_annotations_file = os.path.join(training_mltable_path, \"train_annotations.jsonl\")\n",
    "validation_annotations_file = os.path.join(\n",
    "    validation_mltable_path, \"validation_annotations.jsonl\"\n",
    ")\n",
    "\n",
    "# Baseline of json line dictionary\n",
    "json_line_sample = {\n",
    "    \"image_url\": uri_folder_data_asset.path,\n",
    "    \"image_details\": {\"format\": None, \"width\": None, \"height\": None},\n",
    "    \"label\": [],\n",
    "}\n",
    "\n",
    "# Path to the annotations\n",
    "annotations_folder = os.path.join(dataset_dir, \"annotations\")\n",
    "\n",
    "# Read each annotation and convert it to jsonl line\n",
    "with open(train_annotations_file, \"w\") as train_f:\n",
    "    with open(validation_annotations_file, \"w\") as validation_f:\n",
    "        for i, filename in enumerate(os.listdir(annotations_folder)):\n",
    "            if not filename.endswith(\".xml\"):\n",
    "                print(f\"Skipping unknown file: {filename}\")\n",
    "                continue\n",
    "\n",
    "            annotation_filename = os.path.join(annotations_folder, filename)\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Parsing {annotation_filename}\")\n",
    "\n",
    "            root = ET.parse(annotation_filename).getroot()\n",
    "            width = int(root.find(\"size/width\").text)\n",
    "            height = int(root.find(\"size/height\").text)\n",
    "\n",
    "            labels = []\n",
    "            for object in root.findall(\"object\"):\n",
    "                name = object.find(\"name\").text\n",
    "                xmin = object.find(\"bndbox/xmin\").text\n",
    "                ymin = object.find(\"bndbox/ymin\").text\n",
    "                xmax = object.find(\"bndbox/xmax\").text\n",
    "                ymax = object.find(\"bndbox/ymax\").text\n",
    "                isCrowd = int(object.find(\"difficult\").text)\n",
    "                labels.append(\n",
    "                    {\n",
    "                        \"label\": name,\n",
    "                        \"topX\": float(xmin) / width,\n",
    "                        \"topY\": float(ymin) / height,\n",
    "                        \"bottomX\": float(xmax) / width,\n",
    "                        \"bottomY\": float(ymax) / height,\n",
    "                        \"isCrowd\": isCrowd,\n",
    "                    }\n",
    "                )\n",
    "            # Build the jsonl file\n",
    "            image_filename = root.find(\"filename\").text\n",
    "            _, file_extension = os.path.splitext(image_filename)\n",
    "            json_line = dict(json_line_sample)\n",
    "            json_line[\"image_url\"] = json_line[\"image_url\"] + \"images/\" + image_filename\n",
    "            json_line[\"image_details\"][\"format\"] = file_extension[1:]\n",
    "            json_line[\"image_details\"][\"width\"] = width\n",
    "            json_line[\"image_details\"][\"height\"] = height\n",
    "            json_line[\"label\"] = labels\n",
    "\n",
    "            if i % train_validation_ratio == 0:\n",
    "                # Validation annotation\n",
    "                validation_f.write(json.dumps(json_line) + \"\\n\")\n",
    "            else:\n",
    "                # Train annotation\n",
    "                train_f.write(json.dumps(json_line) + \"\\n\")\n",
    "                \n",
    "# Generate jsonl file from coco file\n",
    "base_url = uri_folder_data_asset.path + \"/images/\"\n",
    "\n",
    "!python resources/training-mmd-object-detection/coco2jsonl.py \\\n",
    "--input_coco_file_path \"./resources/training-mmd-object-detection/odFridgeObjects_coco.json\" \\\n",
    "--output_dir \"./resources/training-mmd-object-detection/data/odFridgeObjects\" \\\n",
    "--output_file_name \"odFridgeObjects_from_coco.jsonl\" \\\n",
    "--task_type \"ObjectDetection\" \\\n",
    "--base_url $base_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ml_table_file(filename):\n",
    "    return (\n",
    "        \"paths:\\n\"\n",
    "        \"  - file: ./{0}\\n\"\n",
    "        \"transformations:\\n\"\n",
    "        \"  - read_json_lines:\\n\"\n",
    "        \"        encoding: utf8\\n\"\n",
    "        \"        invalid_lines: error\\n\"\n",
    "        \"        include_path_column: false\\n\"\n",
    "        \"  - convert_column_types:\\n\"\n",
    "        \"      - columns: image_url\\n\"\n",
    "        \"        column_type: stream_info\"\n",
    "    ).format(filename)\n",
    "\n",
    "def save_ml_table_file(output_path, mltable_file_contents):\n",
    "    with open(os.path.join(output_path, \"MLTable\"), \"w\") as f:\n",
    "        f.write(mltable_file_contents)\n",
    "\n",
    "# Create and save train mltable\n",
    "train_mltable_file_contents = create_ml_table_file(\n",
    "    os.path.basename(train_annotations_file)\n",
    ")\n",
    "save_ml_table_file(training_mltable_path, train_mltable_file_contents)\n",
    "\n",
    "# Save train and validation mltable\n",
    "validation_mltable_file_contents = create_ml_table_file(\n",
    "    os.path.basename(validation_annotations_file)\n",
    ")\n",
    "save_ml_table_file(validation_mltable_path, validation_mltable_file_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the fine tuning job using predefined component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JobException",
     "evalue": "The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/ai/ml/operations/_job_ops_helper.py:291\u001b[39m, in \u001b[36mstream_logs_until_completion\u001b[39m\u001b[34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m current_log \u001b[38;5;129;01min\u001b[39;00m available_logs:\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m     content = \u001b[43mdownload_text_from_url\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_current_logs_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_log\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipeline_with_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRunHistoryConstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_DEFAULT_GET_CONTENT_TIMEOUT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    297\u001b[39m     _incremental_print(content, processed_logs, current_log, file_handle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/ai/ml/_utils/utils.py:221\u001b[39m, in \u001b[36mdownload_text_from_url\u001b[39m\u001b[34m(source_uri, requests_pipeline, timeout)\u001b[39m\n\u001b[32m    219\u001b[39m     timeout_params = {\u001b[33m\"\u001b[39m\u001b[33mread_timeout\u001b[39m\u001b[33m\"\u001b[39m: read_timeout, \u001b[33m\"\u001b[39m\u001b[33mconnection_timeout\u001b[39m\u001b[33m\"\u001b[39m: connect_timeout}\n\u001b[32m--> \u001b[39m\u001b[32m221\u001b[39m response = \u001b[43mrequests_pipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtimeout_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    222\u001b[39m \u001b[38;5;66;03m# Match old behavior from execution service's status API.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/ai/ml/_utils/_http_utils.py:68\u001b[39m, in \u001b[36m_request_function.<locals>._.<locals>.decorated\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     57\u001b[39m request = HttpRequest(\n\u001b[32m     58\u001b[39m     f.\u001b[34m__name__\u001b[39m.upper(),\n\u001b[32m     59\u001b[39m     *args,\n\u001b[32m   (...)\u001b[39m\u001b[32m     65\u001b[39m     files=kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mfiles\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[32m     66\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.http_response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:242\u001b[39m, in \u001b[36mPipeline.run\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    241\u001b[39m first_node = \u001b[38;5;28mself\u001b[39m._impl_policies[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._impl_policies \u001b[38;5;28;01melse\u001b[39;00m _TransportRunner(\u001b[38;5;28mself\u001b[39m._transport)\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfirst_node\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_request\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:98\u001b[39m, in \u001b[36m_SansIOHTTPPolicyRunner.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:98\u001b[39m, in \u001b[36m_SansIOHTTPPolicyRunner.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:98\u001b[39m, in \u001b[36m_SansIOHTTPPolicyRunner.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/policies/_redirect.py:205\u001b[39m, in \u001b[36mRedirectPolicy.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m retryable:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m     redirect_location = \u001b[38;5;28mself\u001b[39m.get_redirect_location(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/policies/_retry.py:545\u001b[39m, in \u001b[36mRetryPolicy.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    544\u001b[39m request.context[\u001b[33m\"\u001b[39m\u001b[33mretry_count\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mlen\u001b[39m(retry_settings[\u001b[33m\"\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m545\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    546\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_retry(retry_settings, response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:98\u001b[39m, in \u001b[36m_SansIOHTTPPolicyRunner.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:98\u001b[39m, in \u001b[36m_SansIOHTTPPolicyRunner.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnext\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/_base.py:130\u001b[39m, in \u001b[36m_TransportRunner.send\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    127\u001b[39m cleanup_kwargs_for_transport(request.context.options)\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m PipelineResponse(\n\u001b[32m    129\u001b[39m     request.http_request,\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sender\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m    131\u001b[39m     context=request.context,\n\u001b[32m    132\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/pipeline/transport/_requests_basic.py:365\u001b[39m, in \u001b[36mRequestsTransport.send\u001b[39m\u001b[34m(self, request, proxies, **kwargs)\u001b[39m\n\u001b[32m    364\u001b[39m     timeout = (connection_timeout, read_timeout)\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnection_verify\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mconnection_cert\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnection_config\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcert\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m response.raw.enforce_content_length = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/opentelemetry/instrumentation/requests/__init__.py:228\u001b[39m, in \u001b[36m_instrument.<locals>.instrumented_send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_http_instrumentation_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_send\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m \u001b[38;5;66;03m# See\u001b[39;00m\n\u001b[32m    231\u001b[39m \u001b[38;5;66;03m# https://github.com/open-telemetry/semantic-conventions/blob/main/docs/http/http-spans.md#http-client\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/requests/adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/opentelemetry/instrumentation/urllib3/__init__.py:327\u001b[39m, in \u001b[36m_instrument.<locals>.instrumented_urlopen\u001b[39m\u001b[34m(wrapped, instance, args, kwargs)\u001b[39m\n\u001b[32m    326\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_http_instrumentation_enabled():\n\u001b[32m--> \u001b[39m\u001b[32m327\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    329\u001b[39m url = _get_url(instance, args, kwargs, url_filter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/urllib3/connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/http/client.py:1411\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1410\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1411\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/http/client.py:324\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    323\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m324\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    325\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/http/client.py:285\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m285\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    286\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/socket.py:707\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    706\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m707\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    708\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/ssl.py:1249\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1246\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1247\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1248\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/ssl.py:1105\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mJobException\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[65]\u001b[39m\u001b[32m, line 116\u001b[39m\n\u001b[32m    111\u001b[39m mmdetection_pipeline_run = workspace_ml_client.jobs.create_or_update(\n\u001b[32m    112\u001b[39m     created_pipeline, experiment_name=experiment_name\n\u001b[32m    113\u001b[39m )\n\u001b[32m    115\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPipeline created. URL: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmmdetection_pipeline_run.studio_url\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m \u001b[43mworkspace_ml_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmmdetection_pipeline_run\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/core/tracing/decorator.py:138\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    136\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m span_attributes.items():\n\u001b[32m    137\u001b[39m                 span.add_attribute(key, value)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# Native path\u001b[39;00m\n\u001b[32m    141\u001b[39m     config = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/ai/ml/_telemetry/activity.py:288\u001b[39m, in \u001b[36mmonitor_with_activity.<locals>.monitor.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    284\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m tracer.start_as_current_span(ACTIVITY_SPAN):\n\u001b[32m    285\u001b[39m         \u001b[38;5;28;01mwith\u001b[39;00m log_activity(\n\u001b[32m    286\u001b[39m             logger.package_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f.\u001b[34m__name__\u001b[39m, activity_type, custom_dimensions\n\u001b[32m    287\u001b[39m         ):\n\u001b[32m--> \u001b[39m\u001b[32m288\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(logger, \u001b[33m\"\u001b[39m\u001b[33mpackage_logger\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    290\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m log_activity(logger.package_logger, activity_name \u001b[38;5;129;01mor\u001b[39;00m f.\u001b[34m__name__\u001b[39m, activity_type, custom_dimensions):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/ai/ml/operations/_job_operations.py:858\u001b[39m, in \u001b[36mJobOperations.stream\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _is_pipeline_child_job(job_object):\n\u001b[32m    856\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PipelineChildJobError(job_id=job_object.id)\n\u001b[32m--> \u001b[39m\u001b[32m858\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_stream_logs_until_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_runs_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjob_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_datastore_operations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequests_pipeline\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_requests_pipeline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/env-lab-azure-handson-machine-learning-001/lib/python3.12/site-packages/azure/ai/ml/operations/_job_ops_helper.py:350\u001b[39m, in \u001b[36mstream_logs_until_completion\u001b[39m\u001b[34m(run_operations, job_resource, datastore_operations, raise_exception_on_failed_job, requests_pipeline)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    344\u001b[39m     error_message = (\n\u001b[32m    345\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe output streaming for the run interrupted.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    346\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mBut the run is still executing on the compute target. \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    347\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mDetails for canceling the run can be found here: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    348\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mhttps://aka.ms/aml-docs-cancel-run\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    349\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m350\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JobException(\n\u001b[32m    351\u001b[39m         message=error_message,\n\u001b[32m    352\u001b[39m         target=ErrorTarget.JOB,\n\u001b[32m    353\u001b[39m         no_personal_data_message=error_message,\n\u001b[32m    354\u001b[39m         error_category=ErrorCategory.USER_ERROR,\n\u001b[32m    355\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mJobException\u001b[39m: The output streaming for the run interrupted.\nBut the run is still executing on the compute target. \nDetails for canceling the run can be found here: https://aka.ms/aml-docs-cancel-run"
     ]
    }
   ],
   "source": [
    "\n",
    "from azure.ai.ml.dsl import pipeline\n",
    "from azure.ai.ml.entities import PipelineComponent\n",
    "from azure.ai.ml import Input\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "pipeline_component_mmdetection_func = registry_ml_client.components.get(\n",
    "    name=\"mmdetection_image_objectdetection_instancesegmentation_pipeline\", label=\"latest\"\n",
    ")\n",
    "\n",
    "deepspeed_config_path = os.path.join(dataset_parent_dir, \"deepspeed_configs/zero1.json\")\n",
    "if not os.path.exists(deepspeed_config_path):\n",
    "    print(\"DeepSpeed config file not found\")\n",
    "    deepspeed_config_path = None\n",
    "\n",
    "pipeline_component_args = {\n",
    "    # # Model import args\n",
    "    \"model_family\": \"MmDetectionImage\",\n",
    "    \"download_from_source\": False,  # True for downloading a model directly from MMDetection\n",
    "    \"mlflow_model\": foundation_model.id,  # foundation_model.id is provided, only foundation_model gives UserErrorException: only path input is supported now but get: ...\n",
    "    # \"model_name\": mmdetection_model_name, # specify the model_name instead of mlflow_model if you want to use a model from the mmdetection model zoo\n",
    "    # Finetune args\n",
    "    \"task_name\": \"image-object-detection\",\n",
    "    \"apply_augmentations\": True,\n",
    "    \"number_of_workers\": 8,\n",
    "    \"apply_deepspeed\": False,\n",
    "    \"deepspeed_config\": deepspeed_config_path,\n",
    "    \"apply_ort\": False,\n",
    "    \"auto_find_batch_size\": False,\n",
    "    \"extra_optim_args\": \"\",\n",
    "    \"precision\": \"32\",\n",
    "    \"random_seed\": 42,\n",
    "    \"evaluation_strategy\": \"epoch\",\n",
    "    \"evaluation_steps\": 500,\n",
    "    \"logging_strategy\": \"epoch\",\n",
    "    \"logging_steps\": 500,\n",
    "    \"save_strategy\": \"epoch\",\n",
    "    \"save_steps\": 500,\n",
    "    \"save_total_limit\": -1,\n",
    "    \"early_stopping\": False,\n",
    "    \"early_stopping_patience\": 1,\n",
    "    \"resume_from_checkpoint\": False,\n",
    "    \"save_as_mlflow_model\": True,\n",
    "    # # Uncomment one or more lines below to provide specific values, if you wish you override the autoselected default values.\n",
    "    # \"image_min_size\": -1,\n",
    "    # \"image_max_size\": -1,\n",
    "    # \"metric_for_best_model\": \"mean_average_precision\",\n",
    "    # \"number_of_epochs\": 15,\n",
    "    # \"max_steps\": -1,\n",
    "    # \"training_batch_size\": 4,\n",
    "    # \"validation_batch_size\": 4,\n",
    "    # \"learning_rate\": 5e-5,\n",
    "    # \"learning_rate_scheduler\": \"warmup_linear\",\n",
    "    # \"warmup_steps\": 0,\n",
    "    # \"optimizer\": \"adamw_hf\",\n",
    "    # \"weight_decay\": 0.0,\n",
    "    # \"gradient_accumulation_step\": 1,\n",
    "    # \"max_grad_norm\": 1.0,\n",
    "    # \"iou_threshold\": 0.5,\n",
    "    # \"box_score_threshold\": 0.3,\n",
    "    # # Model evaluation args\n",
    "    # The following parameters map to the dataset fields\n",
    "    # Uncomment one or more lines below to provide specific values, if you wish you override the autoselected default values.\n",
    "    # \"label_column_name\": \"label\",\n",
    "    # \"input_column_names\": \"image_url\",\n",
    "}\n",
    "instance_count = 1\n",
    "\n",
    "# Ensure that the user provides only one of mlflow_model or model_name\n",
    "use_model_name = aml_registry_model_name\n",
    "print(f\"Finetuning model {use_model_name}\")\n",
    "\n",
    "\n",
    "@pipeline()\n",
    "def create_pipeline_mmdetection():\n",
    "    mmdetection_pipeline_component: PipelineComponent = pipeline_component_mmdetection_func(\n",
    "        compute_model_import=cpu_cluster_name,\n",
    "        compute_finetune=gpu_cluster_name,\n",
    "        compute_model_evaluation=gpu_cluster_name,\n",
    "        training_data=Input(type=AssetTypes.MLTABLE, path=training_mltable_path),\n",
    "        validation_data=Input(type=AssetTypes.MLTABLE, path=validation_mltable_path),\n",
    "        # test data\n",
    "        # Using the same data for validation and test. If you want to use a different dataset for test, specify it below\n",
    "        test_data=Input(type=AssetTypes.MLTABLE, path=validation_mltable_path),\n",
    "        instance_count=instance_count,\n",
    "        process_count_per_instance=gpus_per_node,\n",
    "        **pipeline_component_args,\n",
    "    )\n",
    "\n",
    "\n",
    "    return {\n",
    "        # Map the output of the fine tuning job to the output of pipeline job so that we can easily register the fine tuned model. Registering the model is required to deploy the model to an online or batch endpoint.\n",
    "        \"trained_model\": mmdetection_pipeline_component.outputs.mlflow_model_folder,\n",
    "    }\n",
    "    \n",
    "created_pipeline = create_pipeline_mmdetection()\n",
    "\n",
    "# don't use cached results from previous jobs\n",
    "created_pipeline.settings.force_rerun = True\n",
    "\n",
    "# set continue on step failure to False\n",
    "created_pipeline.settings.continue_on_step_failure = False\n",
    "\n",
    "created_pipeline.display_name = (\n",
    "    use_model_name + \"_mmdetection_pipeline_component_run_\" + \"od\"\n",
    ")\n",
    "# Don't use cached results from previous jobs\n",
    "created_pipeline.settings.force_rerun = True\n",
    "\n",
    "print(\"Submitting pipeline\")\n",
    "\n",
    "mmdetection_pipeline_run = workspace_ml_client.jobs.create_or_update(\n",
    "    created_pipeline, experiment_name=experiment_name\n",
    ")\n",
    "\n",
    "print(f\"Pipeline created. URL: {mmdetection_pipeline_run.studio_url}\")\n",
    "workspace_ml_client.jobs.stream(mmdetection_pipeline_run.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.tracking.client import MlflowClient\n",
    "\n",
    "# Obtain the tracking URL from MLClient\n",
    "MLFLOW_TRACKING_URI = workspace_ml_client.workspaces.get(\n",
    "    name=workspace_ml_client.workspace_name\n",
    ").mlflow_tracking_uri\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\n",
    "print(f\"\\nCurrent tracking uri: {mlflow.get_tracking_uri()}\")\n",
    "\n",
    "# Initialize MLFlow client\n",
    "mlflow_client = MlflowClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml.entities import Model\n",
    "from azure.ai.ml.constants import AssetTypes\n",
    "\n",
    "# Fetch the model from pipeline job output - not working, hence fetching from fine tune child job\n",
    "model_path_from_job = (\n",
    "    f\"azureml://jobs/mmd-3x-yolof_r50_c5_8x8_1x_coco_mmdetection_pipeline_component_run_od/outputs/trained_model\"\n",
    ")\n",
    "print(f\"Path to register model: {model_path_from_job}\")\n",
    "\n",
    "finetuned_model_name = f\"{use_model_name.replace('/', '-')}-fridge-objects-od\"\n",
    "finetuned_model_description = f\"{use_model_name.replace('/', '-')} fine tuned model for fridge objects object detection\"\n",
    "prepare_to_register_model = Model(\n",
    "    path=model_path_from_job,\n",
    "    type=AssetTypes.MLFLOW_MODEL,\n",
    "    name=finetuned_model_name,\n",
    "    version=timestamp,  # Use timestamp as version to avoid version conflict\n",
    "    description=finetuned_model_description,\n",
    ")\n",
    "print(f\"Prepare to register model: \\n{prepare_to_register_model}\")\n",
    "\n",
    "# Register the model from pipeline job output\n",
    "registered_model = workspace_ml_client.models.create_or_update(\n",
    "    prepare_to_register_model\n",
    ")\n",
    "print(f\"Registered model: {registered_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from azure.ai.ml.entities import ManagedOnlineEndpoint, ManagedOnlineDeployment, OnlineRequestSettings, ProbeSettings\n",
    "\n",
    "# Endpoint names need to be unique in a region, hence using timestamp to create unique endpoint name\n",
    "online_endpoint_name = \"mmd-od-fridge-items-\" + datetime.datetime.now().strftime(\"%m%d%H%M\")\n",
    "online_endpoint_description = f\"Online endpoint for {registered_model.name}, finetuned for fridge objects object detection\"\n",
    "# Create an online endpoint\n",
    "endpoint = ManagedOnlineEndpoint(\n",
    "    name=online_endpoint_name,\n",
    "    description=online_endpoint_description,\n",
    "    auth_mode=\"key\",\n",
    ")\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()\n",
    "\n",
    "deployment_name = \"mmd-od-fridge-mlflow-deploy\"\n",
    "print(registered_model.id)\n",
    "print(online_endpoint_name)\n",
    "print(deployment_name)\n",
    "\n",
    "# Create a deployment\n",
    "demo_deployment = ManagedOnlineDeployment(\n",
    "    name=deployment_name,\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    model=registered_model.id,\n",
    "    instance_type=\"Standard_DS3_V2\",\n",
    "    instance_count=1,\n",
    "    request_settings=OnlineRequestSettings(\n",
    "        max_concurrent_requests_per_instance=1,\n",
    "        request_timeout_ms=90000,\n",
    "        max_queue_wait_ms=500,\n",
    "    ),\n",
    "    liveness_probe=ProbeSettings(\n",
    "        failure_threshold=49,\n",
    "        success_threshold=1,\n",
    "        timeout=299,\n",
    "        period=180,\n",
    "        initial_delay=180,\n",
    "    ),\n",
    "    readiness_probe=ProbeSettings(\n",
    "        failure_threshold=10,\n",
    "        success_threshold=1,\n",
    "        timeout=10,\n",
    "        period=10,\n",
    "        initial_delay=10,\n",
    "    ),\n",
    ")\n",
    "workspace_ml_client.online_deployments.begin_create_or_update(demo_deployment).wait()\n",
    "endpoint.traffic = {deployment_name: 100}\n",
    "workspace_ml_client.begin_create_or_update(endpoint).result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import json\n",
    "\n",
    "def read_image(image_path):\n",
    "    with open(image_path, \"rb\") as f:\n",
    "        return f.read()\n",
    "\n",
    "# Get the details for online endpoint\n",
    "endpoint = workspace_ml_client.online_endpoints.get(name=online_endpoint_name)\n",
    "request_file_name = \"sample_request_data.json\"\n",
    "with open(request_file_name, \"w\") as request_file:\n",
    "    json.dump({\n",
    "        \"input_data\": {\n",
    "            \"columns\": [\"image\"],\n",
    "            \"data\": [base64.encodebytes(read_image(os.path.join(dataset_dir, \"images\", \"99.jpg\"))).decode(\"utf-8\")],\n",
    "        }\n",
    "    }, request_file)\n",
    "\n",
    "response = workspace_ml_client.online_endpoints.invoke(\n",
    "    endpoint_name=online_endpoint_name,\n",
    "    deployment_name=deployment_name,\n",
    "    request_file=request_file_name,\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "\n",
    "img_np = mpimg.imread(sample_image)\n",
    "img = Image.fromarray(img_np.astype(\"uint8\"), \"RGB\")\n",
    "x, y = img.size\n",
    "conf_threshold = 0.6  # display top objects with confidence score > 0.6\n",
    "\n",
    "# Set a compact figure size\n",
    "fig_width = 12\n",
    "fig_height = 12\n",
    "\n",
    "# Initialize figure and axes\n",
    "fig = plt.figure(figsize=(fig_width, fig_height))\n",
    "gs = fig.add_gridspec(2, 1, height_ratios=[4, 1], hspace=0.2)\n",
    "ax1 = fig.add_subplot(gs[0])\n",
    "ax2 = fig.add_subplot(gs[1])\n",
    "\n",
    "# Display the image with bounding boxes and segmentation maps\n",
    "ax1.imshow(img_np)\n",
    "ax1.axis(\"off\")\n",
    "\n",
    "# Draw bounding boxes and segmentation maps for each detection\n",
    "detections = json.loads(response)\n",
    "sorted_data = sorted(detections[0][\"boxes\"], key=lambda x: x[\"score\"], reverse=True)\n",
    "sorted_scores = []\n",
    "sorted_colors = []\n",
    "unique_labels = []\n",
    "label_counter = {}\n",
    "\n",
    "# draw box and label for each detection\n",
    "for detect in sorted_data:\n",
    "    label = detect[\"label\"]\n",
    "    box = detect[\"box\"]\n",
    "    conf_score = detect[\"score\"]\n",
    "\n",
    "    if conf_score > conf_threshold:\n",
    "        # Modify labels to make them unique with numbering\n",
    "        if label not in label_counter:\n",
    "            label_counter[label] = 1\n",
    "            unique_labels.append(f\"{label} {label_counter[label]}\")\n",
    "        else:\n",
    "            label_counter[label] += 1\n",
    "            unique_labels.append(f\"{label} {label_counter[label]}\")\n",
    "\n",
    "        current_label = unique_labels[-1]\n",
    "\n",
    "        ymin, xmin, ymax, xmax = (\n",
    "            box[\"topY\"],\n",
    "            box[\"topX\"],\n",
    "            box[\"bottomY\"],\n",
    "            box[\"bottomX\"],\n",
    "        )\n",
    "        topleft_x, topleft_y = x * xmin, y * ymin\n",
    "        width, height = x * (xmax - xmin), y * (ymax - ymin)\n",
    "        print(\n",
    "            f\"{current_label}: [{round(topleft_x, 3)}, {round(topleft_y, 3)}, \"\n",
    "            f\"{round(width, 3)}, {round(height, 3)}], {round(conf_score, 3)}\"\n",
    "        )\n",
    "\n",
    "        color = np.random.rand(3)\n",
    "        rect = patches.Rectangle(\n",
    "            (topleft_x, topleft_y),\n",
    "            width,\n",
    "            height,\n",
    "            linewidth=2,\n",
    "            edgecolor=color,\n",
    "            facecolor=\"none\",\n",
    "        )\n",
    "        ax1.add_patch(rect)\n",
    "        ax1.text(topleft_x, topleft_y - 10, current_label, color=color, fontsize=20)\n",
    "        sorted_scores.append(conf_score)\n",
    "        sorted_colors.append(color)\n",
    "\n",
    "# Set a stylish color palette\n",
    "sns.set_palette(\"pastel\")\n",
    "\n",
    "# Create the bar plot without x-axis and y-axis markings\n",
    "barplot = sns.barplot(x=sorted_scores, y=unique_labels, palette=sorted_colors, ax=ax2)\n",
    "ax2.set_xlabel(\"\")  # Remove x-axis label\n",
    "ax2.set_ylabel(\"\")  # Remove y-axis label\n",
    "ax2.set_title(f\"Top {len(sorted_scores)} Object Scores\", fontsize=12)\n",
    "\n",
    "# Add scores in front of the bars\n",
    "for index, value in enumerate(sorted_scores):\n",
    "    barplot.text(\n",
    "        value + 0.01, index, f\"{value:.2f}\", va=\"center\", color=\"black\", fontsize=10\n",
    "    )\n",
    "\n",
    "# Remove spines and ticks from the bar plot\n",
    "barplot.spines[\"left\"].set_visible(False)\n",
    "barplot.spines[\"top\"].set_visible(False)\n",
    "barplot.spines[\"right\"].set_visible(False)\n",
    "barplot.spines[\"bottom\"].set_visible(False)\n",
    "barplot.tick_params(left=False, top=False, right=False, bottom=False)\n",
    "barplot.xaxis.set_visible(False)  # Remove x-axis\n",
    "barplot.yaxis.grid(False)  # Remove y-axis grid\n",
    "\n",
    "# Set plot background color\n",
    "fig.patch.set_facecolor(\"#F7F7F7\")  # Light gray\n",
    "\n",
    "plt.tight_layout()\n",
    "# fig.savefig(\"plot.png\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_comp = registry_ml_client.components.get(\n",
    "    name=\"mmdetection_image_objectdetection_instancesegmentation_pipeline\",\n",
    "    label=\"latest\"\n",
    ")\n",
    "pipeline_comp.dump(dest=\"./mmdet_pipeline.yaml\")"
   ]
  }
 ],
 "metadata": {
  "description": {
   "description": "Create pipeline with CommandComponents from local YAML file"
  },
  "kernelspec": {
   "display_name": "env-lab-azure-handson-machine-learning-001",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
